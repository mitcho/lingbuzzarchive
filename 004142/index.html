<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en"><head><title>Fusion is great, and interpretable fusion could be exciting for theory generation - lingbuzz/004142</title><meta http-equiv="Content-Type" content="text/html;charset=utf-8"/><meta http-equiv="Content-Script-Type" content="text/javascript"/><link rel="canonical" href="/lingbuzz/004142"/><meta name="description" content="Response to “Generative linguistics and neural networks at 60: foundation, friction, and fusion” by Joe Pater.

From my perspective, Pater’s (2018) target article does a great service to both resear - lingbuzz, the linguistics archive"/><link rel="stylesheet" type="text/css" href="/buzzdocs/styles/article-editor.css"/><link rel="stylesheet" type="text/css" href="/lingbuzz"/></head><body alink="#111111" vlink="#333344" link="#3333AA" onload="onLoad()">&nbsp;<p></p><center><font size="+1"><b><a href="/lingbuzz/004142/current.pdf">Fusion is great, and interpretable fusion could be exciting for theory generation</a></b></font><br/><a href="/lingbuzz/004142">Lisa Pearl</a><br/>July 2018</center>&nbsp;<p></p>Response to “Generative linguistics and neural networks at 60: foundation, friction, and fusion” by Joe Pater.

From my perspective, Pater’s (2018) target article does a great service to both researchers who work in generative linguistics and researchers who utilize neural networks – and especially to researchers who might find themselves wanting to do both by harnessing the insights of each tradition. The article does three very useful things. First, it provides primers with historical overviews of each tradition. Second, it highlights what’s been achieved by the fusion of the generative linguistics theoretical framework and the neural networks modeling technique. Third, it notes the increasing interpretability of neural network models, which I think suggests a very exciting path forward for generating linguistic theories of representation.
<table cellspacing="15" valign="top"><tr><td>Format: </td><td>[ <a href="/lingbuzz/004142/current.pdf">pdf</a> ]</td></tr><tr><td>Reference: </td><td>lingbuzz/004142<br/><font size="-1"> (please use that when you cite this article)</font></td></tr><tr><td>Published in: </td><td>(submitted to Perspectives subsection of Language)</td></tr><tr><td>keywords: </td><td>generative linguistics, neural networks, probabilistic learning, language acquisition, theory generation, bayesian inference, learnability, syntax, phonology, semantics, morphology</td></tr><tr><td>Downloaded:</td><td>95 times</td></tr></table><table cellspacing="15"><tr><p></p>&nbsp;<p></p>[ <a href="/lingbuzz/004142">edit this article</a> | <a href="/lingbuzz/004142">back to article list</a> ]</tr></table><script type="text/javascript">/*<![CDATA[*/function onLoad(){};/*]]>*/</script></body></html>
