<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en"><head><title>A Closer Look at the Performance of Neural Language Models on Reflexive Anaphor Licensing - lingbuzz/004931</title><meta http-equiv="Content-Type" content="text/html;charset=utf-8"/><meta http-equiv="Content-Script-Type" content="text/javascript"/><link rel="canonical" href="/lingbuzz/004931"/><meta name="description" content="An emerging line of work uses psycholinguistic methods to evaluate the syntactic generalizations acquired by neural language models (NLMs). While this approach has shown NLMs to be capable of learning - lingbuzz, the linguistics archive"/><link rel="stylesheet" type="text/css" href="/buzzdocs/styles/article-editor.css"/><link rel="stylesheet" type="text/css" href="/lingbuzz"/></head><body alink="#111111" vlink="#333344" link="#3333AA" onload="onLoad()">&nbsp;<p></p><center><font size="+1"><b><a href="/lingbuzz/004931/current.pdf">A Closer Look at the Performance of Neural Language Models on Reflexive Anaphor Licensing</a></b></font><br/><a href="/lingbuzz/004931">Jennifer Hu</a>, <a href="/lingbuzz/004931">Sherry Yong Chen</a>, <a href="/lingbuzz/004931">Roger Levy</a><br/>December 2019</center>&nbsp;<p></p>An emerging line of work uses psycholinguistic methods to evaluate the syntactic generalizations acquired by neural language models (NLMs). While this approach has shown NLMs to be capable of learning a wide range
of linguistic knowledge, confounds in the design of previous experiments may have obscured the potential of NLMs to learn certain grammatical phenomena. Here we re-evaluate the performance of a range of NLMs on reflexive anaphor licensing. Under our paradigm, the models consistently show stronger evidence of learning than reported in previous work. Our approach demonstrates the value of well-controlled psycholinguistic methods in gaining a fine-grained understanding of NLM learning potential<table cellspacing="15" valign="top"><tr><td>Format: </td><td>[ <a href="/lingbuzz/004931/current.pdf">pdf</a> ]</td></tr><tr><td>Reference: </td><td>lingbuzz/004931<br/><font size="-1"> (please use that when you cite this article)</font></td></tr><tr><td>Published in: </td><td>Proceedings of the Society for Computation in Linguistics (SCiL) 2020, Vol 3</td></tr><tr><td>keywords: </td><td>syntax, reflexives, reflexive licensing, computational modelling, nlp, language models, model evaluation, gender bias, syntax</td></tr><tr><td>Downloaded:</td><td>242 times</td></tr></table><table cellspacing="15"><tr><p></p>&nbsp;<p></p>[ <a href="/lingbuzz/004931">edit this article</a> | <a href="/lingbuzz/004931">back to article list</a> ]</tr></table><script type="text/javascript">/*<![CDATA[*/function onLoad(){};/*]]>*/</script></body></html>