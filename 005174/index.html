<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en"><head><title>CiwGAN and fiwGAN: modeling lexical learning from raw acoustic data in Generative Adversarial Phonology - lingbuzz/005174</title><meta http-equiv="Content-Type" content="text/html;charset=utf-8"/><meta http-equiv="Content-Script-Type" content="text/javascript"/><link rel="canonical" href="/lingbuzz/005174"/><meta name="description" content="This paper proposes two neural network architectures for modeling unsupervised lexical learning from raw acoustic inputs, ciwGAN (Categorical InfoWaveGAN) and fiwGAN (Featural InfoWaveGAN), that combi - lingbuzz, the linguistics archive"/><link rel="stylesheet" type="text/css" href="/buzzdocs/styles/article-editor.css"/><link rel="stylesheet" type="text/css" href="/lingbuzz"/></head><body alink="#111111" vlink="#333344" link="#3333AA" onload="onLoad()">&nbsp;<p></p><center><font size="+1"><b><a href="/lingbuzz/005174/current.pdf">CiwGAN and fiwGAN: modeling lexical learning from raw acoustic data in Generative Adversarial Phonology</a></b></font><br/><a href="/lingbuzz/005174">Gasper Begus</a><br/>May 2020</center>&nbsp;<p></p>This paper proposes two neural network architectures for modeling unsupervised lexical learning from raw acoustic inputs, ciwGAN (Categorical InfoWaveGAN) and fiwGAN (Featural InfoWaveGAN), that combine a Deep Convolutional GAN architecture for audio data (WaveGAN; Donahue et al. 2019) with an information theoretic extension of GAN â€“ InfoGAN (Chen et al., 2016), and introduce featural learning. In addition to the Generator and the Discriminator networks, the architectures introduce a network that learns to retrieve latent codes from generated outputs and forces the Generator to output data such that lexical representations are retrievable from its acoustic outputs. Lexical learning from acoustic inputs is thus modeled as emergent from an architecture that forces a deep neural network to generate data such that unique information is retrievable from its outputs. The networks are trained on highly variable lexical items from TIMIT. The networks learn to generate data and encode unique information corresponding to lexical items in the form of categorical variables in its latent space. By manipulating these categorical variables, the network outputs specific lexical items. The network occasionally outputs innovative lexical items that violate training data, but are linguistically interpretable and offer potential for direct comparison between productivity in human lexical and phonological acquisition and the proposed model. The fiwGAN architecture additionally allows simultaneous modeling of lexical and phonological (featural) representations. Innovative outputs in this architecture suggest that phonetic/phonological features learned by the network can be productively recombined in innovative outputs that violate training data: a fiwGAN network trained on suit and dark outputs start, even though it never saw start or even a [st] sequence in the training data. We also show that setting latent featural codes to values well beyond training range result in almost categorical generation of prototypical lexical items and reveal underlying values of each latent code. The results bear implications for understanding how networks learn meaningful representations as well as a potential for unsupervised text-to-speech generation in the GAN framework.<table cellspacing="15" valign="top"><tr><td>Format: </td><td>[ <a href="/lingbuzz/005174/current.pdf">pdf</a> ]</td></tr><tr><td>Reference: </td><td>lingbuzz/005174<br/><font size="-1"> (please use that when you cite this article)</font></td></tr><tr><td>Published in: </td><td></td></tr><tr><td>keywords: </td><td>artificial intelligence, neural networks, generative adversarial networks, phonetic learning, phonological learning, voice onset time, allophonic distribution, phonology</td></tr><tr><td>Downloaded:</td><td>65 times</td></tr></table><table cellspacing="15"><tr><p></p>&nbsp;<p></p>[ <a href="/lingbuzz/005174">edit this article</a> | <a href="/lingbuzz/005174">back to article list</a> ]</tr></table><script type="text/javascript">/*<![CDATA[*/function onLoad(){};/*]]>*/</script></body></html>
