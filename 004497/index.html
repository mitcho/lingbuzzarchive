<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en"><head><title>A Framework for Decoding Event-Related Potentials from Text - lingbuzz/004497</title><meta http-equiv="Content-Type" content="text/html;charset=utf-8"/><meta http-equiv="Content-Script-Type" content="text/javascript"/><link rel="canonical" href="/lingbuzz/004497"/><meta name="description" content="We propose a novel framework for modeling event-related potentials (ERPs) collected during reading that couples pre-trained convolutional decoders with a language model. Using this framework, we compa - lingbuzz, the linguistics archive"/><link rel="stylesheet" type="text/css" href="/buzzdocs/styles/article-editor.css"/><link rel="stylesheet" type="text/css" href="/lingbuzz"/></head><body alink="#111111" vlink="#333344" link="#3333AA" onload="onLoad()">&nbsp;<p></p><center><font size="+1"><b><a href="/lingbuzz/004497/current.pdf">A Framework for Decoding Event-Related Potentials from Text</a></b></font><br/><a href="/lingbuzz/004497">Shaorong Yan</a>, <a href="/lingbuzz/004497">Aaron Steven White</a><br/>April 2019</center>&nbsp;<p></p>We propose a novel framework for modeling event-related potentials (ERPs) collected during reading that couples pre-trained convolutional decoders with a language model. Using this framework, we compare the abilities of a variety of existing and novel sentence processing models to reconstruct ERPs.  We find that modern contextual word embeddings underperform surprisal-based models but that, combined, the two outperform either on its own.<table cellspacing="15" valign="top"><tr><td>Format: </td><td>[ <a href="/lingbuzz/004497/current.pdf">pdf</a> ]</td></tr><tr><td>Reference: </td><td>lingbuzz/004497<br/><font size="-1"> (please use that when you cite this article)</font></td></tr><tr><td>Published in: </td><td>Proceedings of the 9th Workshop on Cognitive Modeling and Computational Linguistics (CMCL 2019)</td></tr><tr><td>keywords: </td><td>sentence processing, event related potentials, electroencephalography, convolutional neural networks, semantics, syntax</td></tr><tr><td>previous versions: </td><td><a href="/lingbuzz/004497/v3.pdf">v3 [February 2019]</a><br/><a href="/lingbuzz/004497/v2.pdf">v2 [February 2019]</a><br/><a href="/lingbuzz/004497/v1.pdf">v1 [February 2019]</a><br/></td></tr><tr><td>Downloaded:</td><td>559 times</td></tr></table><table cellspacing="15"><tr><p></p>&nbsp;<p></p>[ <a href="/lingbuzz/004497">edit this article</a> | <a href="/lingbuzz/004497">back to article list</a> ]</tr></table><script type="text/javascript">/*<![CDATA[*/function onLoad(){};/*]]>*/</script></body></html>