<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en"><head><title>Linguistic inferences from pro-speech music - lingbuzz/006222</title><meta http-equiv="Content-Type" content="text/html;charset=utf-8"/><meta http-equiv="Content-Script-Type" content="text/javascript"/><link rel="canonical" href="/lingbuzz/006222"/><meta name="description" content="Language has a rich typology of inferential types. It was recently shown that subjects are able to divide the
informational content of new visual stimuli among the various slots of the inferential ty - lingbuzz, the linguistics archive"/><link rel="stylesheet" type="text/css" href="/buzzdocs/styles/article-editor.css"/><link rel="stylesheet" type="text/css" href="/lingbuzz"/></head><body alink="#111111" vlink="#333344" link="#3333AA" onload="onLoad()">&nbsp;<p></p><center><font size="+1"><b><a href="/lingbuzz/006222/current.pdf">Linguistic inferences from pro-speech music</a></b></font><br/><a href="/lingbuzz/006222">Leo Migotti</a>, <a href="/lingbuzz/006222">Janek Guerrini</a><br/>April 2022</center>&nbsp;<p></p>Language has a rich typology of inferential types. It was recently shown that subjects are able to divide the
informational content of new visual stimuli among the various slots of the inferential typology: when gestures
or visual animations are used in lieu of specific words in a sentence, they can trigger the very same inferential
types as language alone (Tieu et al., 2019). How general is the algorithm that divides at-issue from non-at-issue
content? We show that it extends to the auditory modality and to music cognition. We tested whether pro-speech
musical gestures, i.e. musical excerpts that replace words in sentences, can give rise to the same inferences.
We show that it is possible to replicate the same typology of inferences using pro-speech music. Minimal and
complex musical excerpts can behave just like language, gestures, and visual animations with respect to the
logical behavior of their content when embedded in sentences. Specifically, we found that pro-speech music can
generate scalar implicatures, presuppositions, supplements, and homogeneity inferences.<table cellspacing="15" valign="top"><tr><td>Format: </td><td>[ <a href="/lingbuzz/006222/current.pdf">pdf</a> ]</td></tr><tr><td>Reference: </td><td>lingbuzz/006222<br/><font size="-1"> (please use that when you cite this article)</font></td></tr><tr><td>Published in: </td><td>Under review</td></tr><tr><td>keywords: </td><td>pragmatics, music, typology of linguistic inferences, semantics</td></tr><tr><td>previous versions: </td><td><a href="/lingbuzz/006222/v1.pdf">v1 [June 2021]</a><br/></td></tr><tr><td>Downloaded:</td><td>387 times</td></tr></table><table cellspacing="15"><tr><p></p>&nbsp;<p></p>[ <a href="/lingbuzz/006222">edit this article</a> | <a href="/lingbuzz/006222">back to article list</a> ]</tr></table><script type="text/javascript">/*<![CDATA[*/function onLoad(){};/*]]>*/</script></body></html>