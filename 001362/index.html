<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en"><head><title>Power in acceptability judgment experiments and the reliability of data in syntax. - lingbuzz/001362</title><meta http-equiv="Content-Type" content="text/html;charset=utf-8"/><meta http-equiv="Content-Script-Type" content="text/javascript"/><link rel="canonical" href="/lingbuzz/001362"/><meta name="description" content="There has been a consistent pattern of criticism of the reliability of acceptability judgment data in syntax for at least 50 years (e.g., Hill 1961), culminating in several high-profile criticisms wit - lingbuzz, the linguistics archive"/><link rel="stylesheet" type="text/css" href="/buzzdocs/styles/article-editor.css"/><link rel="stylesheet" type="text/css" href="/lingbuzz"/></head><body alink="#111111" vlink="#333344" link="#3333AA" onload="onLoad()">&nbsp;<p></p><center><font size="+1"><b><a href="/lingbuzz/001362/current.pdf">Power in acceptability judgment experiments and the reliability of data in syntax.</a></b></font><br/><a href="/lingbuzz/001362">Jon Sprouse</a>, <a href="/lingbuzz/001362">Diogo Almeida</a><br/>September 2011</center>&nbsp;<p></p>There has been a consistent pattern of criticism of the reliability of acceptability judgment data in syntax for at least 50 years (e.g., Hill 1961), culminating in several high-profile criticisms within the past ten years (e.g., Edelman and Christiansen 2003, Ferreira 2005, Wasow and Arnold 2005, Featherston 2007, Gibson and Fedorenko 2010a, 2010b). One of the fundamental claims of these critics is that traditional acceptability judgment collection methods, lead to an intolerably high number of false negative results (i.e., low statistical power). We empirically assessed this claim by re-testing 95 phenomena that span the full range of effect sizes in syntactic data, estimated from two recent large scale acceptability surveys (Sprouse and Almeida, to appear, and Sprouse, Schutze, and Almeida, submitted) using two different tasks (magnitude estimation, which is commonly used in formal experiments, and forced-choice, which is commonly used in traditional methods), and using resampling simulations to empirically estimate false negative rates (statistical power) for each phenomenon at every sample size between 5 and 100 participants. Contrary to the claims of critics, these results suggest that traditional methods have a remarkably low false negative rate by experimental psychology standards, and in fact are more sensitive than formal experiments at detecting differences between conditions. We discuss the implications of these results for questions about the reliability of syntactic data, as well as the practical consequences of these results for the methodological options available to syntacticians. (Note that this is a substantially revised version of a previous upload called "Power in acceptability judgment experiments")<table cellspacing="15" valign="top"><tr><td>Format: </td><td>[ <a href="/lingbuzz/001362/current.pdf">pdf</a> ]</td></tr><tr><td>Reference: </td><td>lingbuzz/001362<br/><font size="-1"> (please use that when you cite this article, unless you want to cite the full url: <a href="http://ling.auf.net/lingbuzz/001362">http://ling.auf.net/lingbuzz/001362</a>)</font></td></tr><tr><td>keywords: </td><td>acceptability judgments, syntactic theory, linguistic methodology, quantitative standards, experimental syntax, statistical power, syntax</td></tr><tr><td>previous versions: </td><td><a href="/lingbuzz/001362/v1.pdf">v1 [September 2011]</a><br/></td></tr><tr><td>Downloaded:</td><td>739 times</td></tr></table><table cellspacing="15"><tr><p></p>&nbsp;<p></p>[ <a href="/lingbuzz/001362">edit this article</a> | <a href="/lingbuzz/001362">back to article list</a> ]</tr></table><script type="text/javascript">/*<![CDATA[*/function onLoad(){};/*]]>*/</script></body></html>
