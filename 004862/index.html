<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en"><head><title>Acceptability ratings cannot be taken at face value - lingbuzz/004862</title><meta http-equiv="Content-Type" content="text/html;charset=utf-8"/><meta http-equiv="Content-Script-Type" content="text/javascript"/><link rel="canonical" href="/lingbuzz/004862"/><meta name="description" content="This chapter addresses how linguists’ empirical (syntax) claims should be tested with non-linguists. Recent experimental work attempts to measure rates of convergence between data presented in journal - lingbuzz, the linguistics archive"/><link rel="stylesheet" type="text/css" href="/buzzdocs/styles/article-editor.css"/><link rel="stylesheet" type="text/css" href="/lingbuzz"/></head><body alink="#111111" vlink="#333344" link="#3333AA" onload="onLoad()">&nbsp;<p></p><center><font size="+1"><b><a href="/lingbuzz/004862/current.pdf">Acceptability ratings cannot be taken at face value</a></b></font><br/><a href="/lingbuzz/004862">Carson T. Schütze</a><br/>July 2019</center>&nbsp;<p></p>This chapter addresses how linguists’ empirical (syntax) claims should be tested with non-linguists. Recent experimental work attempts to measure rates of convergence between data presented in journal articles and the results of large surveys. The chapter presents three follow-up experiments to one such study (Sprouse, Schütze, and Almeida 2013), arguing that this method may underestimate the true rate of convergence because it leaves considerable room for naïve subjects to give ratings that do not reflect their true acceptability judgments of the relevant structures. To understand what can go wrong, the experiments were conducted in two parts: the first part had visually presented sentences rated on a computer, replicating previous work. The second part was an interview where the experimenter asked each subject about the ratings they gave to particular items, in order to determine what interpretation/parse they had assigned, whether they had missed any critical words, etc.<table cellspacing="15" valign="top"><tr><td>Format: </td><td>[ <a href="/lingbuzz/004862/current.pdf">pdf</a> ]</td></tr><tr><td>Reference: </td><td>lingbuzz/004862<br/><font size="-1"> (please use that when you cite this article)</font></td></tr><tr><td>Published in: </td><td>Published in "Linguistic intuitions: Evidence and method", eds. Samuel Schindler, Anna Drożdżowicz & Karen Brøcker, OUP 2020, pp. 189–214. DOI: 10.1093/oso/9780198840558.003.0011</td></tr><tr><td>keywords: </td><td>acceptability judgments, syntax, linguists vs. non-linguists, rate of convergence, interview, syntax</td></tr><tr><td>Downloaded:</td><td>425 times</td></tr></table><table cellspacing="15"><tr><p></p>&nbsp;<p></p>[ <a href="/lingbuzz/004862">edit this article</a> | <a href="/lingbuzz/004862">back to article list</a> ]</tr></table><script type="text/javascript">/*<![CDATA[*/function onLoad(){};/*]]>*/</script></body></html>