<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en"><head><title>No Such Thing as a General Learner: Language models and their dual optimization - lingbuzz/008355</title><meta http-equiv="Content-Type" content="text/html;charset=utf-8"/><meta http-equiv="Content-Script-Type" content="text/javascript"/><link rel="canonical" href="/lingbuzz/008355"/><meta name="description" content="What role can the otherwise successful Large Language Models (LLMs) play in the understanding of human cognition, and in particular in terms of informing lan-guage acquisition debates? To contribute t - lingbuzz, the linguistics archive"/><link rel="stylesheet" type="text/css" href="/buzzdocs/styles/article-editor.css"/><link rel="stylesheet" type="text/css" href="/lingbuzz"/></head><body alink="#111111" vlink="#333344" link="#3333AA" onload="onLoad()">&nbsp;<p></p><center><font size="+1"><b><a href="/lingbuzz/008355/current.pdf">No Such Thing as a General Learner: Language models and their dual optimization</a></b></font><br/><a href="/lingbuzz/008355">Emmanuel Chemla</a>, <a href="/lingbuzz/008355">Ryan Nefdt</a><br/>August 2024</center>&nbsp;<p></p>What role can the otherwise successful Large Language Models (LLMs) play in the understanding of human cognition, and in particular in terms of informing lan-guage acquisition debates? To contribute to this question, we first argue that neither humans nor LLMs are general learners, in a variety of senses. We make a novel case for how in particular LLMs follow a dual-optimization process: they are optimized during their training (which is typically compared to language acquisition), and modern LLMs have also been selected, through a process akin to natural selection in a species. From this perspective, we argue that the performance of LLMs, whether similar or dissimilar to that of humans, does not weigh easily on important debates about the importance of human cognitive biases for language<table cellspacing="15" valign="top"><tr><td>Format: </td><td>[ <a href="/lingbuzz/008355/current.pdf">pdf</a> ]</td></tr><tr><td>Reference: </td><td>lingbuzz/008355<br/><font size="-1"> (please use that when you cite this article)</font></td></tr><tr><td>Published in: </td><td></td></tr><tr><td>keywords: </td><td>nativism, large language models, impossible languages, dual- optimization, natural selection, semantics, syntax</td></tr><tr><td>previous versions: </td><td><a href="/lingbuzz/008355/v1.pdf">v1 [August 2024]</a><br/></td></tr><tr><td>Downloaded:</td><td>376 times</td></tr></table><table cellspacing="15"><tr><p></p>&nbsp;<p></p>[ <a href="/lingbuzz/008355">edit this article</a> | <a href="/lingbuzz/008355">back to article list</a> ]</tr></table><script type="text/javascript">/*<![CDATA[*/function onLoad(){};/*]]>*/</script></body></html>