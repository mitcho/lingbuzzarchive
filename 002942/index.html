<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en"><head><title>Outline of Music Semantics - lingbuzz/002942</title><meta http-equiv="Content-Type" content="text/html;charset=utf-8"/><meta http-equiv="Content-Script-Type" content="text/javascript"/><link rel="canonical" href="/lingbuzz/002942"/><meta name="description" content="We provide the outline of a semantics for music. We take music cognition to be continuous with normal auditory cognition, and thus to deliver inferences about 'virtual sources' of the music (as in Bre - lingbuzz, the linguistics archive"/><link rel="stylesheet" type="text/css" href="/buzzdocs/styles/article-editor.css"/><link rel="stylesheet" type="text/css" href="/lingbuzz"/></head><body alink="#111111" vlink="#333344" link="#3333AA" onload="onLoad()">&nbsp;<p></p><center><font size="+1"><b><a href="/lingbuzz/002942/current.pdf">Outline of Music Semantics</a></b></font><br/><a href="/lingbuzz/002942">Philippe Schlenker</a><br/>July 2017</center>&nbsp;<p></p>We provide the outline of a semantics for music. We take music cognition to be continuous with normal auditory cognition, and thus to deliver inferences about 'virtual sources' of the music (as in Bregman's Auditory Scene Analysis). As a result, sound parameters that trigger inferences about sound sources in normal auditory cognition produce related ones in music – as is the case when decreasing loudness signals the end of a piece because the source is gradually losing energy, or moving away. But what is special about music is that it also triggers inferences on the basis of the movement of virtual sources in tonal pitch space, which has points of stability (e.g., a tonic chord), points of instability (e.g., dissonant chords), and relations of attractions among them (e.g., a dissonant chord tends to be resolved). In this way, gradual movement towards a point of tonal stability, as in a cadence, may also serve to signal the end of a piece, but on the basis of tonal information. The challenge is thus to develop a framework that aggregates inferences from normal auditory cognition and tonal inferences. We sketch such a framework in a highly simplified case, by arguing that a source undergoing a musical movement m is true of an object undergoing a series of events e just in case there is a certain structure-preserving map between m and e. Thus we require that inferences triggered by loudness on the relative levels of energy or proximity among events should be preserved, and similarly for tonal inferences pertaining to the relative stability of events. This yields a 'bare bones' version of a music semantics, as well as a definition of 'musical truth'.  We then argue that this framework can help re-visit some aspects of musical syntax. Specifically, we take (Lerdahl & Jackendoff's, 1983) grouping structure to reflect the mereology ('partology') of events that are abstractly represented in the music – hence the importance of Gestalt principles of perception in defining musical groups.  Finally, we argue that this 'referentialist' approach to music semantics still has the potential to provide an account of diverse emotional effects in music.<table cellspacing="15" valign="top"><tr><td>Format: </td><td>[ <a href="/lingbuzz/002942/current.pdf">pdf</a> ]</td></tr><tr><td>Reference: </td><td>lingbuzz/002942<br/><font size="-1"> (please use that when you cite this article)</font></td></tr><tr><td>Published in: </td><td>Music Perception 2017</td></tr><tr><td>keywords: </td><td>music semantics, music pragmatics, iconicity, source-based semantics, semantics</td></tr><tr><td>previous versions: </td><td><a href="/lingbuzz/002942/v8.pdf">v8 [July 2017]</a><br/><a href="/lingbuzz/002942/v7.pdf">v7 [January 2017]</a><br/><a href="/lingbuzz/002942/v6.pdf">v6 [December 2016]</a><br/><a href="/lingbuzz/002942/v5.pdf">v5 [December 2016]</a><br/><a href="/lingbuzz/002942/v4.pdf">v4 [December 2016]</a><br/><a href="/lingbuzz/002942/v3.pdf">v3 [May 2016]</a><br/><a href="/lingbuzz/002942/v2.pdf">v2 [May 2016]</a><br/><a href="/lingbuzz/002942/v1.pdf">v1 [April 2016]</a><br/></td></tr><tr><td>Downloaded:</td><td>5000 times</td></tr></table><table cellspacing="15"><tr><p></p>&nbsp;<p></p>[ <a href="/lingbuzz/002942">edit this article</a> | <a href="/lingbuzz/002942">back to article list</a> ]</tr></table><script type="text/javascript">/*<![CDATA[*/function onLoad(){};/*]]>*/</script></body></html>