<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en"><head><title>Assessing the reliability of journal data in syntax: Linguistic Inquiry 2001-2010 - lingbuzz/001352</title><meta http-equiv="Content-Type" content="text/html;charset=utf-8"/><meta http-equiv="Content-Script-Type" content="text/javascript"/><link rel="canonical" href="/lingbuzz/001352"/><meta name="description" content="There has been a consistent pattern of criticism of the reliability of acceptability judgment data in syntax for at least 50 years (e.g., Hill 1961), culminating in several high-profile criticisms wit - lingbuzz, the linguistics archive"/><link rel="stylesheet" type="text/css" href="/buzzdocs/styles/article-editor.css"/><link rel="stylesheet" type="text/css" href="/lingbuzz"/></head><body alink="#111111" vlink="#333344" link="#3333AA" onload="onLoad()">&nbsp;<p></p><center><font size="+1"><b><a href="/lingbuzz/001352/current.pdf">Assessing the reliability of journal data in syntax: Linguistic Inquiry 2001-2010</a></b></font><br/><a href="/lingbuzz/001352">Jon Sprouse</a>, <a href="/lingbuzz/001352">Carson T. Schütze</a>, <a href="/lingbuzz/001352">Diogo Almeida</a><br/>September 2011</center>&nbsp;<p></p>There has been a consistent pattern of criticism of the reliability of acceptability judgment data in syntax for at least 50 years (e.g., Hill 1961), culminating in several high-profile criticisms within the past ten years (e.g., Edelman and Christiansen 2003, Ferreira 2005, Wasow and Arnold 2005, Gibson and Fedorenko 2010a, 2010b). The fundamental claim of these critics is that traditional acceptability judgment collection methods, which tend to be relatively informal compared to methods from experimental psychology, lead to an intolerably high number of false positive results. In this paper we empirically assess this claim by formally testing a random sample of 292 sentence types that form 146 two-condition phenomena taken from the most recent ten years of articles in a leading journal of theoretical linguistics (Linguistic Inquiry 2001-2010). We report the results of two experiments designed to assess the replication rate of these 146 phenomena under formal experimental methods (Experiment 1 used the magnitude estimation task and 168 participants, Experiment 2 used the forced-choice task and 96 participants). 139 of the 146 phenomena, or 95%, replicated in the formal experiments (with a margin of error of ±5%). This means that even under the (likely unwarranted) assumption that all of the discrepant results are false positives that have found their way into the syntactic literature due to the shortcomings of traditional methods, the maximum proportion of such false positives in LI 2001-2010 is 5% (±5%). We discuss the implications of these results for questions about the reliability of syntactic data, as well as the practical consequences of these results for the methodological options available to syntacticians.<table cellspacing="15" valign="top"><tr><td>Format: </td><td>[ <a href="/lingbuzz/001352/current.pdf">pdf</a> ]</td></tr><tr><td>Reference: </td><td>lingbuzz/001352<br/><font size="-1"> (please use that when you cite this article)</font></td></tr><tr><td>keywords: </td><td>acceptability judgments, syntactic theory, linguistic methodology, quantitative standards, experimental syntax, syntax</td></tr><tr><td>Downloaded:</td><td>976 times</td></tr></table><table cellspacing="15"><tr><p></p>&nbsp;<p></p>[ <a href="/lingbuzz/001352">edit this article</a> | <a href="/lingbuzz/001352">back to article list</a> ]</tr></table><script type="text/javascript">/*<![CDATA[*/function onLoad(){};/*]]>*/</script></body></html>
