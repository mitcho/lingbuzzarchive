<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en"><head><title>How statistical learning can play well with Universal Grammar - lingbuzz/004772</title><meta http-equiv="Content-Type" content="text/html;charset=utf-8"/><meta http-equiv="Content-Script-Type" content="text/javascript"/><link rel="canonical" href="/lingbuzz/004772"/><meta name="description" content="One motivation for Universal Grammar (UG) is that it’s what allows children to acquire the linguistic knowledge that they do as quickly as they do from the data that’s available to them.  One key lega - lingbuzz, the linguistics archive"/><link rel="stylesheet" type="text/css" href="/buzzdocs/styles/article-editor.css"/><link rel="stylesheet" type="text/css" href="/lingbuzz"/></head><body alink="#111111" vlink="#333344" link="#3333AA" onload="onLoad()">&nbsp;<p></p><center><font size="+1"><b><a href="/lingbuzz/004772/current.pdf">How statistical learning can play well with Universal Grammar</a></b></font><br/><a href="/lingbuzz/004772">Lisa Pearl</a><br/>December 2019</center>&nbsp;<p></p>One motivation for Universal Grammar (UG) is that it’s what allows children to acquire the linguistic knowledge that they do as quickly as they do from the data that’s available to them.  One key legacy of Chomsky’s work in language acquisition is highlighting the separation between children’s hypothesis space of possible representations (typically defined by UG) and how children might navigate that hypothesis space (sometimes defined by UG). While statistical learning is sometimes thought to be at odds with UG, I review how statistical learning can both complement UG and help us refine our ideas about the contents of UG. I first review some cognitively-plausible statistical learning mechanisms that can operate over a predefined hypothesis space, like those UG creates. I then review two sets of examples: (i) those where statistical learning allows more efficient navigation through a UG-defined hypothesis space, and (ii) those where statistical learning can replace prior UG proposals for navigating a hypothesis space, and in turn lead to new ideas about how UG might construct the hypothesis space in the first place. I conclude with a brief discussion of how we might make progress on understanding language acquisition by incorporating statistical learning into our UG-based acquisition theories.<table cellspacing="15" valign="top"><tr><td>Format: </td><td>[ <a href="/lingbuzz/004772/current.pdf">pdf</a> ]</td></tr><tr><td>Reference: </td><td>lingbuzz/004772<br/><font size="-1"> (please use that when you cite this article)</font></td></tr><tr><td>Published in: </td><td>Wiley-Blackwell Companion to Chomsky (after review)</td></tr><tr><td>keywords: </td><td>universal grammar, statistical learning, linguistic parameters, parameter setting, linking theories, subset principle, syntactic islands, reinforcement learning, variational learning, tolerance principle, sufficiency principle, bayesian inference, morphology, syntax, phonology</td></tr><tr><td>previous versions: </td><td><a href="/lingbuzz/004772/v2.pdf">v2 [September 2019]</a><br/><a href="/lingbuzz/004772/v1.pdf">v1 [September 2019]</a><br/></td></tr><tr><td>Downloaded:</td><td>236 times</td></tr></table><table cellspacing="15"><tr><p></p>&nbsp;<p></p>[ <a href="/lingbuzz/004772">edit this article</a> | <a href="/lingbuzz/004772">back to article list</a> ]</tr></table><script type="text/javascript">/*<![CDATA[*/function onLoad(){};/*]]>*/</script></body></html>
