<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en"><head><title> Squibbing Against Continuity Claims in Artificial Intelligence: Why We Can’t Get There From Here <> The Pursuit of Recursive Neurons - lingbuzz/007354</title><meta http-equiv="Content-Type" content="text/html;charset=utf-8"/><meta http-equiv="Content-Script-Type" content="text/javascript"/><link rel="canonical" href="/lingbuzz/007354"/><meta name="description" content="The fact that the brain is made up of neurons doesn’t tell us much about the underlying representational mode upon which human thought is delivered, nor does it account for whether there are analogs t - lingbuzz, the linguistics archive"/><link rel="stylesheet" type="text/css" href="/buzzdocs/styles/article-editor.css"/><link rel="stylesheet" type="text/css" href="/lingbuzz"/></head><body alink="#111111" vlink="#333344" link="#3333AA" onload="onLoad()">&nbsp;<p></p><center><font size="+1"><b><a href="/lingbuzz/007354/current.pdf"> Squibbing Against Continuity Claims in Artificial Intelligence: Why We Can’t Get There From Here &lt;&gt; The Pursuit of Recursive Neurons</a></b></font><br/><a href="/lingbuzz/007354">Joseph Galasso</a><br/>June 2023</center>&nbsp;<p></p>The fact that the brain is made up of neurons doesn’t tell us much about the underlying representational mode upon which human thought is delivered, nor does it account for whether there are analogs to computer-software procedures as found in Artificial Intelligence (AI). The arguments herein contrast two types of neuronal delivery systems (local v distant, serial v parallel) in determining how short-term memory (hippocampus) tethers to ‘local-domain’ connectionist models, while long-term memory (cortex) tethers to ‘distant-domain’ symbolic models: thus, any putative interface which seeks to model the human global thought-process must require a hybrid model. <table cellspacing="15" valign="top"><tr><td>Format: </td><td>[ <a href="/lingbuzz/007354/current.pdf">pdf</a> ]</td></tr><tr><td>Reference: </td><td>lingbuzz/007354<br/><font size="-1"> (please use that when you cite this article)</font></td></tr><tr><td>Published in: </td><td></td></tr><tr><td>keywords: </td><td>artificial intelligence, recursive neurons, syntax, dual mechanism model, semantics, syntax</td></tr><tr><td>Downloaded:</td><td>344 times</td></tr></table><table cellspacing="15"><tr><p></p>&nbsp;<p></p>[ <a href="/lingbuzz/007354">edit this article</a> | <a href="/lingbuzz/007354">back to article list</a> ]</tr></table><script type="text/javascript">/*<![CDATA[*/function onLoad(){};/*]]>*/</script></body></html>