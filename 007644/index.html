<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en"><head><title>Systematic polysemy in adjective-noun combination in contextual word embeddings - lingbuzz/007644</title><meta http-equiv="Content-Type" content="text/html;charset=utf-8"/><meta http-equiv="Content-Script-Type" content="text/javascript"/><link rel="canonical" href="/lingbuzz/007644"/><meta name="description" content="In this work, we find evidence that masked language models such as BERT vary their representations of adjectives in a manner that reflects non-trivial theoretical predictions made by linguistic semant - lingbuzz, the linguistics archive"/><link rel="stylesheet" type="text/css" href="/buzzdocs/styles/article-editor.css"/><link rel="stylesheet" type="text/css" href="/lingbuzz"/></head><body alink="#111111" vlink="#333344" link="#3333AA" onload="onLoad()">&nbsp;<p></p><center><font size="+1"><b><a href="/lingbuzz/007644/current.pdf">Systematic polysemy in adjective-noun combination in contextual word embeddings</a></b></font><br/><a href="/lingbuzz/007644">Michael Goodale</a>, <a href="/lingbuzz/007644">Salvador Mascarenhas</a><br/>October 2023</center>&nbsp;<p></p>In this work, we find evidence that masked language models such as BERT vary their representations of adjectives in a manner that reflects non-trivial theoretical predictions made by linguistic semantic theories about how adjectives compose with nouns. For example, “skilled surgeon” and “skilled carpenter” are skilled in different ways, whereas a “French surgeon” and “French carpenter” are French in the same way. Crucially, we demonstrate via a simple probe that the variation of the adjective depends on the noun in question for adjectives like “skilled” and the noun is not useful for predicting the variation of adjectives like “French”. We also show that this variation is systematic—it extends to novel nouns unseen in training. These novel nouns are generated by a process we call “nonce-embeddings”, a technique which samples novel embeddings from the manifold of embeddings of nouns in order to generate “meaningless” words akin to nonce-words like wug or blicket used in linguistics and psychology.<table cellspacing="15" valign="top"><tr><td>Format: </td><td>[ <a href="/lingbuzz/007644/current.pdf">pdf</a> ]</td></tr><tr><td>Reference: </td><td>lingbuzz/007644<br/><font size="-1"> (please use that when you cite this article)</font></td></tr><tr><td>Published in: </td><td></td></tr><tr><td>keywords: </td><td>word embeddings, adjectives, subsective, intersective, intensional, probing, language models, bert, distributional semantics, polysemy, semantics</td></tr><tr><td>Downloaded:</td><td>285 times</td></tr></table><table cellspacing="15"><tr><p></p>&nbsp;<p></p>[ <a href="/lingbuzz/007644">edit this article</a> | <a href="/lingbuzz/007644">back to article list</a> ]</tr></table><script type="text/javascript">/*<![CDATA[*/function onLoad(){};/*]]>*/</script></body></html>