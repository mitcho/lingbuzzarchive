<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en"><head><title>Adapting the visual world paradigm to sign languages: asymmetries in LSF relative clause processing - lingbuzz/005847</title><meta http-equiv="Content-Type" content="text/html;charset=utf-8"/><meta http-equiv="Content-Script-Type" content="text/javascript"/><link rel="canonical" href="/lingbuzz/005847"/><meta name="description" content="This paper presents the rst cross-modal investigation of subject and object relative clause processing using the Visual World Paradigm (VWP) for written and signed stimuli. We adapt the original audi - lingbuzz, the linguistics archive"/><link rel="stylesheet" type="text/css" href="/buzzdocs/styles/article-editor.css"/><link rel="stylesheet" type="text/css" href="/lingbuzz"/></head><body alink="#111111" vlink="#333344" link="#3333AA" onload="onLoad()">&nbsp;<p></p><center><font size="+1"><b><a href="/lingbuzz/005847/current.pdf">Adapting the visual world paradigm to sign languages: asymmetries in LSF relative clause processing</a></b></font><br/><a href="/lingbuzz/005847">Hauser Charlotte</a>, <a href="/lingbuzz/005847">CÃ©line Pozniak</a><br/>March 2021</center>&nbsp;<p></p>This paper presents the rst cross-modal investigation of subject and object relative clause processing using the Visual World Paradigm (VWP) for written and signed stimuli. We adapt the original audio-visual VWP paradigm to a visual-only display to make it suitable to the investigation of sign languages.
We test the viability of this adaptation on an already well-studied population: French native speakers. In this first experiment, we use videos displaying written French stimuli to see if participants are able to both look at the stimuli and perform the VWP task of xating one of two pictures. Crucially, we show that this new visual-only display replicates the results obtained with the original audio-visual design from Pozniak (2018): in both paradigms subject relative clauses are easier to process than object relative clauses in French. This first experiment conrms the reliability of the visual-only VWP. We then present the innovative use of the Visual (only) World Paradigm to investigate for the first time asymmetries in the processing of subject and object relative clauses in a sign language, French Sign Language, with signed sentences as stimuli. The
results offer in depth insights both on the linguistics of sign languages and on psycholinguistic research methods.<table cellspacing="15" valign="top"><tr><td>Format: </td><td>[ <a href="/lingbuzz/005847/current.pdf">pdf</a> ]</td></tr><tr><td>Reference: </td><td>lingbuzz/005847<br/><font size="-1"> (please use that when you cite this article)</font></td></tr><tr><td>Published in: </td><td>preprint of Journal of Memory and Language</td></tr><tr><td>keywords: </td><td>eye-tracking, visual world paradigm, french sign language, subject and object relative clause processing, french, syntax</td></tr><tr><td>Downloaded:</td><td>266 times</td></tr></table><table cellspacing="15"><tr><p></p>&nbsp;<p></p>[ <a href="/lingbuzz/005847">edit this article</a> | <a href="/lingbuzz/005847">back to article list</a> ]</tr></table><script type="text/javascript">/*<![CDATA[*/function onLoad(){};/*]]>*/</script></body></html>