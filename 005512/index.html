<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en"><head><title>Now you hear me, later you don’t: The Immediacy of Linguistic Computation and the Representation of Speech - lingbuzz/005512</title><meta http-equiv="Content-Type" content="text/html;charset=utf-8"/><meta http-equiv="Content-Script-Type" content="text/javascript"/><link rel="canonical" href="/lingbuzz/005512"/><meta name="description" content="(Published in Psychological Science: https://doi.org/10.1177/0956797620968787)

What happens to an acoustic signal after it enters the mind of a listener? Previous work has demonstrated that listene - lingbuzz, the linguistics archive"/><link rel="stylesheet" type="text/css" href="/buzzdocs/styles/article-editor.css"/><link rel="stylesheet" type="text/css" href="/lingbuzz"/></head><body alink="#111111" vlink="#333344" link="#3333AA" onload="onLoad()">&nbsp;<p></p><center><font size="+1"><b><a href="/lingbuzz/005512/current.pdf">Now you hear me, later you don’t: The Immediacy of Linguistic Computation and the Representation of Speech</a></b></font><br/><a href="/lingbuzz/005512">Spencer Caplan</a>, <a href="/lingbuzz/005512">Alon Hafri</a>, <a href="/lingbuzz/005512">John Trueswell</a><br/>August 2020</center>&nbsp;<p></p>(Published in Psychological Science: https://doi.org/10.1177/0956797620968787)

What happens to an acoustic signal after it enters the mind of a listener? Previous work has demonstrated that listeners maintain intermediate representations over time. However, the internal structure of such representations—be they the acoustic-phonetic signal or more general information about the probability of possible categories—remains underspecified. We present two experiments using a novel speaker-adaptation paradigm aimed at uncovering the format of speech representations. We exposed adult listeners (N = 297) to a speaker whose utterances contained acoustically ambiguous information concerning phones (and thus words), and we manipulated the temporal availability of disambiguating cues via visually presented text (presented before or after each utterance). Results from a traditional phoneme-categorization task showed that listeners adapted to a modified acoustic distribution when disambiguating text was provided before but not after the audio. These results support the position that speech representations consist of activation over categories and are inconsistent with direct maintenance of the acoustic-phonetic signal.<table cellspacing="15" valign="top"><tr><td>Format: </td><td>[ <a href="/lingbuzz/005512/current.pdf">pdf</a> ]</td></tr><tr><td>Reference: </td><td>lingbuzz/005512<br/><font size="-1"> (please use that when you cite this article)</font></td></tr><tr><td>Published in: </td><td>Psychological Science</td></tr><tr><td>keywords: </td><td>speech processing, immediacy of computation, mental representation, acoustic maintenance, phonology</td></tr><tr><td>Downloaded:</td><td>384 times</td></tr></table><table cellspacing="15"><tr><p></p>&nbsp;<p></p>[ <a href="/lingbuzz/005512">edit this article</a> | <a href="/lingbuzz/005512">back to article list</a> ]</tr></table><script type="text/javascript">/*<![CDATA[*/function onLoad(){};/*]]>*/</script></body></html>