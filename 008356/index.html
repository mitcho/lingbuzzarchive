<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en"><head><title>ChatGPT as an Informant - lingbuzz/008356</title><meta http-equiv="Content-Type" content="text/html;charset=utf-8"/><meta http-equiv="Content-Script-Type" content="text/javascript"/><link rel="canonical" href="/lingbuzz/008356"/><meta name="description" content="While previous machine learning protocols have failed to achieve even observational adequacy in acquiring natural language, generative large language models (LLMs) now produce large amounts of free te - lingbuzz, the linguistics archive"/><link rel="stylesheet" type="text/css" href="/buzzdocs/styles/article-editor.css"/><link rel="stylesheet" type="text/css" href="/lingbuzz"/></head><body alink="#111111" vlink="#333344" link="#3333AA" onload="onLoad()">&nbsp;<p></p><center><font size="+1"><b><a href="/lingbuzz/008356/current.pdf">ChatGPT as an Informant</a></b></font><br/><a href="/lingbuzz/008356">Iris Mulders</a>, <a href="/lingbuzz/008356">E.G. Ruys</a><br/>July 2024</center>&nbsp;<p></p>While previous machine learning protocols have failed to achieve even observational adequacy in acquiring natural language, generative large language models (LLMs) now produce large amounts of free text with few grammatical errors. This is surprising in view of what is known as “the logical problem of language acquisition”. Given the likely absence of negative evidence in the training process, how would the LLM acquire the information that certain strings are to be avoided as ill-formed? We attempt to employ Dutch-speaking ChatGPT as a linguistic informant by capitalizing on the documented “few shot learning” ability of LLM’s. We then investigate whether ChatGPT has acquired familiar island constraints, in particular the CNPC, and compare its performance to that of native speakers. Although descriptive and explanatory adequacy may remain out of reach, initial results indicate that ChatGPT performs well over chance in detecting island violations.<table cellspacing="15" valign="top"><tr><td>Format: </td><td>[ <a href="/lingbuzz/008356/current.pdf">pdf</a> ]</td></tr><tr><td>Reference: </td><td>lingbuzz/008356<br/><font size="-1"> (please use that when you cite this article)</font></td></tr><tr><td>Published in: </td><td>Nota Bene</td></tr><tr><td>keywords: </td><td>llm, gpt, chatgpt, island conditions, negative evidence, poverty of the stimulus, pos, cnpc, adjunct islands, island constraints, wh-movement, syntax</td></tr><tr><td>Downloaded:</td><td>250 times</td></tr></table><table cellspacing="15"><tr><p></p>&nbsp;<p></p>[ <a href="/lingbuzz/008356">edit this article</a> | <a href="/lingbuzz/008356">back to article list</a> ]</tr></table><script type="text/javascript">/*<![CDATA[*/function onLoad(){};/*]]>*/</script></body></html>