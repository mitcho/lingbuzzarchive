<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en"><head><title>Why Linguistics Will Thrive in the 21st Century: A Reply to Piantadosi (2023) - lingbuzz/007485</title><meta http-equiv="Content-Type" content="text/html;charset=utf-8"/><meta http-equiv="Content-Script-Type" content="text/javascript"/><link rel="canonical" href="/lingbuzz/007485"/><meta name="description" content="We present a critical assessment of Piantadosi’s (2023) claim that “Modern language models refute Chomsky’s approach to language,” focusing on four main points. First, despite the impressive performan - lingbuzz, the linguistics archive"/><link rel="stylesheet" type="text/css" href="/buzzdocs/styles/article-editor.css"/><link rel="stylesheet" type="text/css" href="/lingbuzz"/></head><body alink="#111111" vlink="#333344" link="#3333AA" onload="onLoad()">&nbsp;<p></p><center><font size="+1"><b><a href="/lingbuzz/007485/current.pdf">Why Linguistics Will Thrive in the 21st Century: A Reply to Piantadosi (2023)</a></b></font><br/><a href="/lingbuzz/007485">Jordan Kodner</a>, <a href="/lingbuzz/007485">Sarah Payne</a>, <a href="/lingbuzz/007485">Jeffrey Heinz</a><br/>September 2023</center>&nbsp;<p></p>We present a critical assessment of Piantadosi’s (2023) claim that “Modern language models refute Chomsky’s approach to language,” focusing on four main points. First, despite the impressive performance and utility of large language models (LLMs), humans achieve their capacity for language after exposure to several orders of magnitude less data. The fact that young children become competent, fluent speakers of their native languages with relatively little exposure to them is the central mystery of language learning to which Chomsky initially drew attention, and LLMs currently show little promise of solving this mystery. Second, what can the artificial reveal about the natural? Put simply, the implications of LLMs for our understanding of the cognitive structures and mechanisms underlying language and its acquisition are like the implications of airplanes for understanding how birds fly. Third, LLMs cannot constitute scientific theories of language for several reasons, not least of which is that scientific theories must provide interpretable explanations, not just predictions. This leads to our final point: to even determine whether the linguistic and cognitive capabilities of LLMs rival those of humans requires explicating what humans’ capacities actually are. In other words, it requires a separate theory of language and cognition; generative linguistics provides precisely such a theory. As such, we conclude that generative linguistics as a scientific discipline will remain indispensable throughout the 21st century and beyond.

The current version includes a short postscript responding to the reply in the latest version of Piantadosi (2023).<table cellspacing="15" valign="top"><tr><td>Format: </td><td>[ <a href="/lingbuzz/007485/current.pdf">pdf</a> ]</td></tr><tr><td>Reference: </td><td>lingbuzz/007485<br/><font size="-1"> (please use that when you cite this article)</font></td></tr><tr><td>Published in: </td><td></td></tr><tr><td>keywords: </td><td>large language model, minimalism, chomsky, generative syntax, emergent, computational modeling, statistical learning, cognitive science, syntax, morphology, syntax</td></tr><tr><td>previous versions: </td><td><a href="/lingbuzz/007485/v1.pdf">v1 [August 2023]</a><br/></td></tr><tr><td>Downloaded:</td><td>1406 times</td></tr></table><table cellspacing="15"><tr><p></p>&nbsp;<p></p>[ <a href="/lingbuzz/007485">edit this article</a> | <a href="/lingbuzz/007485">back to article list</a> ]</tr></table><script type="text/javascript">/*<![CDATA[*/function onLoad(){};/*]]>*/</script></body></html>