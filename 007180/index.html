<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en"><head><title>Modern language models refute Chomsky’s approach to language - lingbuzz/007180</title><meta http-equiv="Content-Type" content="text/html;charset=utf-8"/><meta http-equiv="Content-Script-Type" content="text/javascript"/><link rel="canonical" href="/lingbuzz/007180"/><meta name="description" content="Modern machine learning has subverted and bypassed the theoretical framework of Chomsky’s generative approach to linguistics, including its core claims to particular insights, principles, structures,  - lingbuzz, the linguistics archive"/><link rel="stylesheet" type="text/css" href="/buzzdocs/styles/article-editor.css"/><link rel="stylesheet" type="text/css" href="/lingbuzz"/></head><body alink="#111111" vlink="#333344" link="#3333AA" onload="onLoad()">&nbsp;<p></p><center><font size="+1"><b><a href="/lingbuzz/007180/current.pdf">Modern language models refute Chomsky’s approach to language</a></b></font><br/><a href="/lingbuzz/007180">Steven Piantadosi</a><br/>July 2024</center>&nbsp;<p></p>Modern machine learning has subverted and bypassed the theoretical framework of Chomsky’s generative approach to linguistics, including its core claims to particular insights, principles, structures, and processes. I describe the sense in which modern language models implement genuine theories of language, and I highlight the links between these models and approaches to linguistics that are based on gradient computations and memorized constructions. I also describe why these models undermine strong claims for the innateness of language and respond to several critiques of large language models, including arguments that they can’t answer “why” questions and skepticism that they are informative about real life acquisition. Most notably, large language models have attained remarkable success at discovering grammar without using any of the methods that some in linguistics insisted were necessary for a science of language to progress. (UPDATED: With a postscript on replies to the original draft)<table cellspacing="15" valign="top"><tr><td>Format: </td><td>[ <a href="/lingbuzz/007180/current.pdf">pdf</a> ]</td></tr><tr><td>Reference: </td><td>lingbuzz/007180<br/><font size="-1"> (please use that when you cite this article)</font></td></tr><tr><td>Published in: </td><td></td></tr><tr><td>keywords: </td><td>large language model, minimalism, chomsky, generative syntax, emergent, computational modeling, statistical learning, cognitive science, syntax</td></tr><tr><td>previous versions: </td><td><a href="/lingbuzz/007180/v7.pdf">v7 [November 2023]</a><br/><a href="/lingbuzz/007180/v6.pdf">v6 [October 2023]</a><br/><a href="/lingbuzz/007180/v5.pdf">v5 [September 2023]</a><br/><a href="/lingbuzz/007180/v4.pdf">v4 [March 2023]</a><br/><a href="/lingbuzz/007180/v3.pdf">v3 [March 2023]</a><br/><a href="/lingbuzz/007180/v2.pdf">v2 [March 2023]</a><br/><a href="/lingbuzz/007180/v1.pdf">v1 [March 2023]</a><br/></td></tr><tr><td>Downloaded:</td><td>28484 times</td></tr></table><table cellspacing="15"><tr><p></p>&nbsp;<p></p>[ <a href="/lingbuzz/007180">edit this article</a> | <a href="/lingbuzz/007180">back to article list</a> ]</tr></table><script type="text/javascript">/*<![CDATA[*/function onLoad(){};/*]]>*/</script></body></html>