<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en"><head><title>The Quo Vadis of the Relationship between Language and Large Language Models - lingbuzz/007659</title><meta http-equiv="Content-Type" content="text/html;charset=utf-8"/><meta http-equiv="Content-Script-Type" content="text/javascript"/><link rel="canonical" href="/lingbuzz/007659"/><meta name="description" content="In the field of Artificial (General) Intelligence (AI), the several recent advancements in Natural language processing (NLP) activities relying on Large Language Models (LLMs) have come to encourage t - lingbuzz, the linguistics archive"/><link rel="stylesheet" type="text/css" href="/buzzdocs/styles/article-editor.css"/><link rel="stylesheet" type="text/css" href="/lingbuzz"/></head><body alink="#111111" vlink="#333344" link="#3333AA" onload="onLoad()">&nbsp;<p></p><center><font size="+1"><b><a href="/lingbuzz/007659/current.pdf">The Quo Vadis of the Relationship between Language and Large Language Models</a></b></font><br/><a href="/lingbuzz/007659">Evelina Leivada</a>, <a href="/lingbuzz/007659">Vittoria Dentella</a>, <a href="/lingbuzz/007659">Elliot Murphy</a><br/>October 2023</center>&nbsp;<p></p>In the field of Artificial (General) Intelligence (AI), the several recent advancements in Natural language processing (NLP) activities relying on Large Language Models (LLMs) have come to encourage the adoption of LLMs as scientific models of language. While the terminology employed for the characterization of LLMs favors their embracing as such, it is not clear that they are in a place to offer insights into the target system they seek to represent. After identifying the most important theoretical and empirical risks brought about by the adoption of scientific models that lack transparency, we discuss LLMs relating them to every scientific modelâ€™s fundamental components: the object, the medium, the meaning and the user. We conclude that, at their current stage of development, LLMs hardly offer any explanations for language, and then we provide an outlook for more informative future research directions on this topic.<table cellspacing="15" valign="top"><tr><td>Format: </td><td>[ <a href="/lingbuzz/007659/current.pdf">pdf</a> ]</td></tr><tr><td>Reference: </td><td>lingbuzz/007659<br/><font size="-1"> (please use that when you cite this article)</font></td></tr><tr><td>Published in: </td><td>arXiv:2310.11146</td></tr><tr><td>keywords: </td><td>large language models, bias, risk, processing, syntax</td></tr><tr><td>Downloaded:</td><td>380 times</td></tr></table><table cellspacing="15"><tr><p></p>&nbsp;<p></p>[ <a href="/lingbuzz/007659">edit this article</a> | <a href="/lingbuzz/007659">back to article list</a> ]</tr></table><script type="text/javascript">/*<![CDATA[*/function onLoad(){};/*]]>*/</script></body></html>