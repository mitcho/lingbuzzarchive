<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en"><head><title>Evaluating the Existence Proof: LLMs as Cognitive Models of Language Acquisition - lingbuzz/008277</title><meta http-equiv="Content-Type" content="text/html;charset=utf-8"/><meta http-equiv="Content-Script-Type" content="text/javascript"/><link rel="canonical" href="/lingbuzz/008277"/><meta name="description" content="In recent years, the technological success of large language models (LLMs) has been taken as an existence proof that language acquisition may succeed without  domain-specific principles and constraint - lingbuzz, the linguistics archive"/><link rel="stylesheet" type="text/css" href="/buzzdocs/styles/article-editor.css"/><link rel="stylesheet" type="text/css" href="/lingbuzz"/></head><body alink="#111111" vlink="#333344" link="#3333AA" onload="onLoad()">&nbsp;<p></p><center><font size="+1"><b><a href="/lingbuzz/008277/current.pdf">Evaluating the Existence Proof: LLMs as Cognitive Models of Language Acquisition</a></b></font><br/><a href="/lingbuzz/008277">Hector Javier Vazquez Martinez</a>, <a href="/lingbuzz/008277">Annika Heuser</a>, <a href="/lingbuzz/008277">Charles Yang</a>, <a href="/lingbuzz/008277">Jordan Kodner</a><br/>July 2024</center>&nbsp;<p></p>In recent years, the technological success of large language models (LLMs) has been taken as an existence proof that language acquisition may succeed without  domain-specific principles and constraints. While this argument acknowledges the important differences between LLM training and child language acquisition, its validity rests on the validity of the existence proof itself, that LLMs indeed demonstrate capacity comparable to human linguistic knowledge, the terminal state of the acquisition process. We contend that such a proof has not been delivered, in large part due to the lack of rigor in LLM evaluation and the absence of serious engagement with the empirical study of child language. When trained on child-scale input data and evaluated on widely used benchmarks, LLMs can be readily matched by simple baseline models that are demonstrably inadequate for human language. As a partial remedy, we advocate for the use of thoroughly validated datasets that more accurately reflect the scope of linguistic knowledge. On these datasets, even LLMs trained on very large amounts of data perform  in a way inconsistent with human behavior. The burden of an existence proof is considerably heavier than previously realized. <table cellspacing="15" valign="top"><tr><td>Format: </td><td>[ <a href="/lingbuzz/008277/current.pdf">pdf</a> ]</td></tr><tr><td>Reference: </td><td>lingbuzz/008277<br/><font size="-1"> (please use that when you cite this article)</font></td></tr><tr><td>Published in: </td><td>Forthcoming. In Artificial Knowledge of Language. José-Luis Mendívil-Giró, editor. Vernon Press</td></tr><tr><td>keywords: </td><td>computational linguistics, cognitive modeling, language acquisition, llm, llms, neural networks, benchmarking, evaluation, methodology, syntax, syntax</td></tr><tr><td>Downloaded:</td><td>854 times</td></tr></table><table cellspacing="15"><tr><p></p>&nbsp;<p></p>[ <a href="/lingbuzz/008277">edit this article</a> | <a href="/lingbuzz/008277">back to article list</a> ]</tr></table><script type="text/javascript">/*<![CDATA[*/function onLoad(){};/*]]>*/</script></body></html>